{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Библиотеки-и-первичное-прочтение-файла\" data-toc-modified-id=\"Библиотеки-и-первичное-прочтение-файла-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Библиотеки и первичное прочтение файла</a></span></li><li><span><a href=\"#Подготовка-признаков\" data-toc-modified-id=\"Подготовка-признаков-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовка признаков</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Линейная-регрессия\" data-toc-modified-id=\"Линейная-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Линейная регрессия</a></span></li><li><span><a href=\"#LGBM\" data-toc-modified-id=\"LGBM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LGBM</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moD3EpaH7MCO"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Привет! Меня зовут Никита Мишин и я буду твоим ревьюером по этому проекты.\n",
    "Для простоты предлагаю общение на 'ты'. Буду предполагать, что ты не против:) \n",
    "Если более предпочтительно обращение на 'Вы', пиши, не стесняйся.\n",
    "Также если будут возникать вопросы, аналогично, пиши:)\n",
    "\n",
    "Предлагаю работать в известном тебе итеративном формате.\n",
    "Итерация состоит в моей проверке твоего решения. \n",
    "После решения могут остаться какие-то недочеты, которые я попрошу тебя устранить, ты их исправляешь и я проверяю твои решения.\n",
    "    Оставленные мною комментарии могут быть разного вида:\n",
    "   \n",
    "    - зеленый: элегантные решения, которые тебе стоит запомнит и в дальнейшем взять на вооружение:) \n",
    "    \n",
    "    - желтый: сигнал о том, что есть некритичная вещь(не всегда ошибка), что нужно точно поправить в следующей работе, даже желательно в этой (полезно, в первую очередь, для тебя:) ).Также это рекомендации на будущее    \n",
    "\n",
    "    - красный: недочет, который нужно исправить в этой работе, для того, чтобы она была принята\n",
    "    \n",
    "    - синий: полезная информация, доп ресурсы, \"вопросы на подумать\"\n",
    "\n",
    "Также попрошу не удалять мои комментарии:) <a class=\"tocSkip\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l02qJWJB0LV"
   },
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJbSp9nlB0LX"
   },
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-SRwRTtB0LZ"
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FSjJlIvB0La"
   },
   "source": [
    "### Библиотеки и первичное прочтение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HKOC44veB0Lb",
    "outputId": "462a8092-c2d4-459f-a0d7-f718dcda401f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hwoy_YAB0Lf"
   },
   "source": [
    "загрузили библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7zfZaOLe6yA",
    "outputId": "3dcb0061-98b2-4467-dfe1-72e1e53af938"
   },
   "outputs": [],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /root/.local/bin/mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5v_3tMrJQl"
   },
   "source": [
    "**специально загрузил версию младше, со старшей вешался google colab на лемматизации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SxqmHfoXB0Lh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFfdMLuKB0Lk"
   },
   "source": [
    "загрузили файл, посмотрим ближе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "tDL1mtHKB0Ln",
    "outputId": "a8d8e8f6-33d8-451a-e559-decb58e54d4a"
   },
   "outputs": [
    {
     "data": {},
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "e91hO5I_7qH1",
    "outputId": "272ee74e-ecda-4b98-ba5f-792aab4e9809"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n = 5, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnV1lDJ27MCf"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Еще иногда полезно использовать метод sample с зафиксированным random_state --- будет выдавать случайные строки датасета</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Io4v_uk58C3o"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий учащегося <a class=\"tocSkip\"></a></h1>\n",
    "\n",
    "Спасибо за идею, взял на вооружение!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTfKlktoB0Lo",
    "outputId": "ca53ab3c-1fdc-4ca2-ba1e-c3b8e9767e52"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfHU0WB3B0Lp"
   },
   "source": [
    "Файл достаточно большой, содержит почти 160 000 строк, важно учитывать при тяжких задачах. При этом у нас классическая задача классификации текста. Есть признак text, который необходимо подготовить, а также у нас есть целевой признак toxic с большим перекосом значений (9 к 1), что может быть проблемой для достижения заданной f-меры. Для начала разберёмся со столбцом text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbYtAz2j7MCg"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-succes\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Да, налицо явный дисбаланс классов</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlYKqbtTB0Lq"
   },
   "source": [
    "### Подготовка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvfspRdAB0Lq"
   },
   "source": [
    "Подготовим функции и создадим новый столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SJRK5vWbB0Ls"
   },
   "outputs": [],
   "source": [
    "# df['text'] = df['text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oClT701I7MCh"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "А зачем нам юникод? У нас ведь чисто английский текст</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1iE38U9-iP7"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<h1>Комментарий учащегося <a class=\"tocSkip\"></a></h1>\n",
    "\n",
    "Честно я и не понял зачем) пробовал и с ним и без, ничего не менялось, но раз в тренажере было с ним - сделал так :) убрал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmeUFkr4Gk_k"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера v2 <a class=\"tocSkip\"></a></h1>\n",
    ";)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ee0UHQwhXaqw"
   },
   "outputs": [],
   "source": [
    "# m = Mystem()\n",
    "\n",
    "# def clear_lemm_text(text):\n",
    "#     filtro = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "#     splito = filtro.split()\n",
    "#     clearo = ' '.join(splito)\n",
    "#     lemm_list = m.lemmatize(clearo)\n",
    "#     lemm_text = ' '.join(lemm_list)\n",
    "#     return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PUK_YNraDiQ9"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def clear_lemm_text_word(text):\n",
    "    filtro = re.sub(r'[^a-zA-Z]', ' ', str(text))\n",
    "    splito = filtro.split()\n",
    "    # clearo = ' '.join(splito)\n",
    "    lemm_list = list()\n",
    "    for w in nltk.word_tokenize(' '.join(splito)):\n",
    "        lemmm_uno = lemmatizer.lemmatize(w, get_wordnet_pos(w))\n",
    "        lemm_list.append(lemmm_uno)\n",
    "    lemm_text = ' '.join(lemm_list)\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IL1EuqBrnqu8",
    "outputId": "16376036-d38e-403c-b4ae-ec11c60b7815"
   },
   "outputs": [],
   "source": [
    "clifff = df['text'].head().apply(clear_lemm_text_word)\n",
    "print(clifff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-3ZNUHNGk_l"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<h1>Комментарий ревьюера v2 <a class=\"tocSkip\"></a></h1>\n",
    "Мне кажется, тут надо в word_tokenize посылать текст, а ты туда лист слов посылаешь, а потом надо добавить:\n",
    "\n",
    "    import nltk\n",
    "    \n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    \n",
    "    \n",
    "У меня вон шайтан машин внизу завелась))\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaNEJJ-LJ_Cn"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<h1>Комментарий учащегося v2 <a class=\"tocSkip\"></a></h1>\n",
    "\n",
    "\n",
    "Загрузил этот tagger, передал список - вроде все работает. Выполняется правда жуть как долго (20 минут) и модельки по качеству хуже, чем с mystem, но работает :) спасибо большое!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h1>Комментарий ревьюера v3 <a class=\"tocSkip\"></a></h1>\n",
    "Ну, pymstem  вроде просто ничего не делал даже)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9F8CtcB6abNF"
   },
   "outputs": [],
   "source": [
    "# df['text'] = df['text'].astype(str)\n",
    "df['ready_word_text'] = df['text'].apply(clear_lemm_text_word)\n",
    "# df['text'].head().apply(clear_lemm_text_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "VArQKhX5Gk_l",
    "outputId": "4afa8aa0-437c-4164-b088-e855052a7f69"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEZ2xGoS7MCi"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "1) Если не ошибаюсь pymystem вроде для русского текста. Попробуй WordNetLemmatizeкr\n",
    "\n",
    "2) Мы ведь должны применять лемматизацию отдельно к слову, а не предложению\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiT0DAHNFLd7"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h1>Комментарий учащегося <a class=\"tocSkip\"></a></h1>\n",
    "\n",
    "\n",
    "0. **Почему-то выдаёт ошибку на re.sub, при том, что я его не менял. Ошибка TypeError: expected string or bytes-like object, пытался по разному ему давать - всё равно не хочет. Сможешь помочь/натокнуть на мысль? я 4 часа потратил на гугление и эксперименты, но так и не понял, что у меня не так. Поэтому сделал проект рабочим и потом запустил эти 2 ячейки для ошибки**\n",
    "1. Вроде бы pymystem может и в английский, но не уверен. Взял wordnet с pos (честно скорее копировал из источника, почему он в return у get_wordnet_pos берёт именно wordnet.NOUN - я не понял). Еще ругался на nltk.download('punkt'), я ему скачал - но я же перед этим очищаю текст на всё кроме букв, что ему не нравится?\n",
    "2. Взял функцию ровно из тренажера (там тоже было на предложениях). Предполагаю, что он сам как-то делит внутри и лемматизирует слова. для wordnet добавил цикл на слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EODTSJqsGk_m"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера v2 <a class=\"tocSkip\"></a></h1>\n",
    "Отписался выше)\n",
    "\n",
    "1.2 нужно немного контекста пример ошибки или не работающего кода, так сложно понять))\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eRKNwuWaGk_m"
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQkeOhTu7MCi"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "За название переменных отдельный лайк, оценил)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZU68muLB0Lv"
   },
   "source": [
    "теперь пройдёмся по столбцу и создадим новый (очищенный и лемматизированны), готовый к использованию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mXbS7ax-B0Lw"
   },
   "outputs": [],
   "source": [
    "# df['ready_text'] = df['text'].apply(clear_lemm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spq4vfdWB0Lw"
   },
   "source": [
    "теперь поделим на обучающую и тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5bshZLDyB0Lx"
   },
   "outputs": [],
   "source": [
    "features = df['ready_word_text']\n",
    "target = df['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size = 0.25, random_state = 12345, stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHUj10FN7MCj"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Забыл указать параметр startify--- отвечает за то, чтобы исходное соотношение классов строго сохранялось в полученных выборках</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axth9Pd4An86"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h1>Комментарий учащегося <a class=\"tocSkip\"></a></h1>\n",
    "\n",
    "Добавил, думал он учитывает по умолчанию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNOF8EVVGk_n"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера v2 <a class=\"tocSkip\"></a></h1>\n",
    "Круто, что добавил</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GATiGIQYB0Lx"
   },
   "source": [
    "подготовка готова, перейдём к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7xqXNY37MCk"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Круто было бы визуализировать слова из разных классов посредством WordCloud --- было бы очень наглядно</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydqiDWctB-Bs"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h1>Комментарий учащегося <a class=\"tocSkip\"></a></h1>\n",
    "\n",
    "Для меня оказалось тяжеловато для изучения (не понял до конца как ему в итоге передать слова, когда это не одна строка), поставил себе в бэклог помучить, спасибо за идею! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wPvgQ0RGk_n"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера v2 <a class=\"tocSkip\"></a></h1>\n",
    "Ок)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8zr10njB0Ly"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDSQ6XLDB0Ly"
   },
   "source": [
    "Воспользуемся 2 моделями:\n",
    "\n",
    "- Линейная регрессия\n",
    "- LGBM\n",
    "\n",
    "(Тут было двухчасовое мучение с Catboost и google colab, но сражение было проиграно)\n",
    "\n",
    "Для начала создадим признаки с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V74d1DpFB0Lz",
    "outputId": "e075d945-9251-4d18-f407-868f318e4c09"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords, ngram_range=(1, 2)) \n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_test = count_tf_idf.transform(features_test)\n",
    "\n",
    "print('Размер train:', tf_idf_train.shape)\n",
    "print('Размер test:', tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L6P9Y7fr4l3"
   },
   "source": [
    "Признаки созданы, перейдём к моделям\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYbH8z2SDjPW"
   },
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LJUHQkNxxlk"
   },
   "source": [
    "Для начала посмотрим на необходимость балансирования весов классов. Запустим 2 версии модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hApxrWakDuZp",
    "outputId": "30c232b7-e815-40c5-ef05-a50f54c68e95"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_LR = LogisticRegression()\n",
    "train_f1 = cross_val_score(model_LR, \n",
    "                      tf_idf_train, \n",
    "                      target_train, \n",
    "                      cv=3, \n",
    "                      scoring='f1').mean()\n",
    "print('F1 на CV', train_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qlQcNztGT2L",
    "outputId": "4a5cf014-0dfb-459e-d0c1-da129aaafc9f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_LR_balanced = LogisticRegression(class_weight='balanced')\n",
    "train_f1 = cross_val_score(model_LR_balanced, \n",
    "                      tf_idf_train, \n",
    "                      target_train, \n",
    "                      cv=3, \n",
    "                      scoring='f1').mean()\n",
    "print('F1 на CV', train_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiOdMGeiyCxb"
   },
   "source": [
    "Невооруженным взглядом видно, насколько баланс важен. Будем использовать только эту модель. На основе неё запустим перебор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlhUL7ah7MCn"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Угу</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enRYOXy1ygOL",
    "outputId": "6f2f82fa-4c24-433d-c4a7-4fa6a9729703"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(max_iter = 1000, class_weight='balanced')\n",
    "lr_params = {'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "             'C':[0.1, 1, 10]}\n",
    "\n",
    "clf_lr = GridSearchCV(estimator = lr, param_grid = lr_params, scoring='f1', cv = 3)\n",
    "\n",
    "clf_lr.fit(tf_idf_train, target_train)\n",
    "\n",
    "print(clf_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiNG2coj-jrY"
   },
   "source": [
    "Лучшие параметры найдены, посмотрим на получившийся F1 на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L0hM0NBGURi",
    "outputId": "a16ce420-d0fe-4d54-8349-b8da4dd84c8c"
   },
   "outputs": [],
   "source": [
    "# clf_lr.fit(tf_idf_train, target_train)\n",
    "\n",
    "lr_predict = clf_lr.predict(tf_idf_test)\n",
    "\n",
    "print('F1 =', f1_score(target_test, lr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KarGY8EvB0L0"
   },
   "source": [
    "Несмотря на долгий подбор, модель Линейной регрессии справилась с заданным порогом метрики f1 в 0.75, показав результат в 0.790"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d9mYZs-7MCp"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Бейзлайн успешно побит, поздравляю!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzZD4XDK7fJF"
   },
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTQojfMm7t3P"
   },
   "source": [
    "Теперь попробуем LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-CtNI1f7x7Y",
    "outputId": "c46f621b-76e4-4b52-d346-edb8aa34a5e0"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "LGBM = LGBMClassifier(class_weight='balanced')\n",
    "parametrs_LGBM = {'n_estimators' : [100],\n",
    "              'depth' : [15, 5],\n",
    "              'learning_rate' : [0.2],\n",
    "              'random_state' : [12345]}\n",
    "clf_LGBM = GridSearchCV(estimator = LGBM, param_grid = parametrs_LGBM, scoring='f1', cv = 3)\n",
    "\n",
    "clf_LGBM.fit(tf_idf_train, target_train)\n",
    "\n",
    "print(clf_LGBM.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4umXk1MzI9zt"
   },
   "source": [
    "Лучшие параметры найдены, посмотрим какую метрику покаже модель на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyif9lVlGHgU",
    "outputId": "3bb54bf3-c1b3-4951-83c2-b636ac501f65"
   },
   "outputs": [],
   "source": [
    "lgbm3 = LGBMClassifier(n_estimators = 100,\n",
    "              depth = 15,\n",
    "            learning_rate = 0.2,\n",
    "              random_state = 12345)\n",
    "\n",
    "lgbm3.fit(tf_idf_train, target_train)\n",
    "\n",
    "LGBM3_predict = lgbm3.predict(tf_idf_test)\n",
    "\n",
    "print('F1 =', f1_score(target_test, LGBM3_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OL-SzDzJLfZ"
   },
   "source": [
    "LGBM показал отличный результат по F1 в 0.773, что также побило требуемый уровень в 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P-KehbVB0L0"
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWq9MVcnJZ4q"
   },
   "source": [
    "**По результатам исследования подобрана лучшая модель - это модель Линейной Регрессии с гиперпараметрами: max_iter = 1000, class_weight='balanced', C = 10, solver = lbfgs! . Она показала F1 выше требуемого (0.790)**\n",
    "\n",
    "*Важный комментарий: в целевом признаке наблюдается сильный дисбаланс, положительных признаков (токсичных комментариев) всего лишь 10% от общего числа! В связи с этим проверка на адекватность не проводилась, требуемый показатель F1 достаточно определяет целесообразность модели*\n",
    "\n",
    "В процессе исследования мы провели лемматизацию и очищение текстов, а также провели создание признаков с помощью TF-IDF, после чего протестировали 2 модели с разными гиперпараметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzdB9kTF7MCq"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Круто было бы еще сводную табличку сделать)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsfvDX8MHC3D"
   },
   "source": [
    "*P.S.Чесно говоря проект дико нервничал-делал, жесткий дедлайн 7-го числа и боюсь не успеть до него закрыть. Всё очень тяжелое и очень долго работает, впервые у меня не получилось сделать проект в самом тренажере. Я уже и с катбустом намучился и просто с обычными фитами пока перебирал гиперы вручную (просто афк по 10-20 минут). Начал делать берт, но у меня совсем начало всё виснуть даже на супернебольших выборках. Может я что-то делаю не так?) Сможете натолкнуть?)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PshmS73b7MCr"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Понял принял, запомнил, увижу на перепроврке --- сразу проерять сяду. \n",
    "\n",
    "Не переживай, тут осталось совсем чуть-чуть подправить)\n",
    "\n",
    "\n",
    "С бертом --- тяжелая махина, хорошо бы свою машинку мощную иметь или времени иметь много) А так ссылочки могу покидать полезные для чтива на след итерации. Кидать?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6sHAVo2CeSR"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h1>Комментарий учащегося <a class=\"tocSkip\"></a></h1>\n",
    "\n",
    "1. Мне тут сказали, что если я на первичную проверку закинул раньше 7-го, то всё ок и можно не так торопиться) Но спасибо тебе большое за понимание!\n",
    "2. Да, покидай плз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psxv94TYGk_q"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<h1>Комментарий ревьюера v2 <a class=\"tocSkip\"></a></h1>\n",
    "Хах, ок)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKkIidA-Gk_q"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h1> Комментарий ревьюера v2 <a class=\"tocSkip\"></h1>\n",
    "Полезное чтиво:\n",
    "    \n",
    "Для работы с текстами используют и другие подходы. \n",
    "Cейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). \n",
    "НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из \n",
    "классического ML тоже могут справляться. \\\n",
    "BERT тяжелее, да, но порой очень нужен. И существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers, они как раз работают нормально по скорости. \n",
    "Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\n",
    "\n",
    "Пачка полезных ссылок\n",
    "\n",
    "1)<a href ='https://huggingface.co/transformers/model_doc/bert.html'>туть</a>\n",
    "\n",
    "2)<a href='https://t.me/renat_alimbekov'>туть</a>\n",
    "\n",
    "2) <a href='https://colah.github.io/posts/2015-08-Understanding-LSTMs'>Про LSTM</a>\n",
    "\n",
    "3) <a href='https://web.stanford.edu/~jurafsky/slp3/10.pdf'> про энкодер-декодер модели, этеншены </a>\n",
    "\n",
    "4) <a href = 'https://pytorch.org/tutorials/beginner/transformer_tutorial.html'> оф гайд по трансформеру от создателей pytorch </a>\n",
    "\n",
    "\n",
    "5) <a href = 'https://transformer.huggingface.co/'> поболтать с трансформером </a>\n",
    "\n",
    "6) Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множество реализованных\n",
    "методов для трансформеров методов NLP\n",
    "\n",
    "6') Отдельно выделю библиотеку TRAX, от гугла\n",
    "    \n",
    "7) курсы на <a href='https://stepik.org/course/54098'>степик</a> и  <a href='https://www.coursera.org/specializations/natural-language-processing'>coursera</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7t5jK71BB0L0"
   },
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSuQCeJs7MCr"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> Комментарий ревьюера <a class=\"tocSkip\"></a></h2>\n",
    "\n",
    "-Спасибо за качественно сделанный проект, было приятно проверять.\n",
    "\n",
    "- Код написан хорошо \n",
    "\n",
    "- Соблюдена структура проекта \n",
    "\n",
    "- Оставил пару советов и комментариев\n",
    "\n",
    "- Нужно немного доработать проект:\n",
    "    \n",
    "    - лемматизация\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2T4oVZ_B0L1"
   },
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdSR3-Dm7eZb"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h1>Комментарий ревьюера <a class=\"tocSkip\"></a></h1>\n",
    "Спасибо за качественную доработку проекта и удачи в следующих проектах!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUreQcvcGk_Z",
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Библиотеки-и-первичное-прочтение-файла\" data-toc-modified-id=\"Библиотеки-и-первичное-прочтение-файла-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Библиотеки и первичное прочтение файла</a></span></li><li><span><a href=\"#Подготовка-признаков\" data-toc-modified-id=\"Подготовка-признаков-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовка признаков</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Линейная-регрессия\" data-toc-modified-id=\"Линейная-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Линейная регрессия</a></span></li><li><span><a href=\"#LGBM\" data-toc-modified-id=\"LGBM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LGBM</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1602,
    "start_time": "2021-08-04T16:51:33.965Z"
   },
   {
    "duration": 3472,
    "start_time": "2021-08-04T16:54:24.853Z"
   },
   {
    "duration": 2044,
    "start_time": "2021-08-04T16:54:32.620Z"
   },
   {
    "duration": 728,
    "start_time": "2021-08-04T16:55:04.491Z"
   },
   {
    "duration": 45,
    "start_time": "2021-08-04T16:55:21.480Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T17:00:57.930Z"
   },
   {
    "duration": 322,
    "start_time": "2021-08-04T20:39:39.864Z"
   },
   {
    "duration": 261,
    "start_time": "2021-08-04T20:40:14.508Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-04T20:40:32.206Z"
   },
   {
    "duration": 1592,
    "start_time": "2021-08-04T20:41:14.698Z"
   },
   {
    "duration": 938,
    "start_time": "2021-08-04T20:41:16.292Z"
   },
   {
    "duration": 57,
    "start_time": "2021-08-04T20:41:17.234Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T20:41:17.294Z"
   },
   {
    "duration": 1536,
    "start_time": "2021-08-04T20:43:05.017Z"
   },
   {
    "duration": 684,
    "start_time": "2021-08-04T20:43:06.556Z"
   },
   {
    "duration": 59,
    "start_time": "2021-08-04T20:43:07.246Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T20:43:07.308Z"
   },
   {
    "duration": 1599,
    "start_time": "2021-08-04T20:43:25.461Z"
   },
   {
    "duration": 763,
    "start_time": "2021-08-04T20:43:27.062Z"
   },
   {
    "duration": 70,
    "start_time": "2021-08-04T20:43:27.829Z"
   },
   {
    "duration": 12,
    "start_time": "2021-08-04T20:43:27.903Z"
   },
   {
    "duration": 2672,
    "start_time": "2021-08-04T20:43:27.918Z"
   },
   {
    "duration": 17,
    "start_time": "2021-08-04T20:43:30.592Z"
   },
   {
    "duration": 424,
    "start_time": "2021-08-04T20:43:30.612Z"
   },
   {
    "duration": 259,
    "start_time": "2021-08-04T20:45:22.370Z"
   },
   {
    "duration": 1532,
    "start_time": "2021-08-04T20:46:43.539Z"
   },
   {
    "duration": 702,
    "start_time": "2021-08-04T20:46:45.073Z"
   },
   {
    "duration": 45,
    "start_time": "2021-08-04T20:46:45.782Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T20:46:45.830Z"
   },
   {
    "duration": 3,
    "start_time": "2021-08-04T20:46:45.841Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T20:46:45.847Z"
   },
   {
    "duration": 5,
    "start_time": "2021-08-04T20:46:45.883Z"
   },
   {
    "duration": 1566,
    "start_time": "2021-08-04T20:46:45.891Z"
   },
   {
    "duration": 1548,
    "start_time": "2021-08-04T20:47:16.016Z"
   },
   {
    "duration": 690,
    "start_time": "2021-08-04T20:47:17.566Z"
   },
   {
    "duration": 55,
    "start_time": "2021-08-04T20:47:18.259Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-04T20:47:18.317Z"
   },
   {
    "duration": 3,
    "start_time": "2021-08-04T20:47:18.328Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T20:47:18.333Z"
   },
   {
    "duration": 40,
    "start_time": "2021-08-04T20:47:18.342Z"
   },
   {
    "duration": 1600,
    "start_time": "2021-08-04T20:51:30.083Z"
   },
   {
    "duration": 744,
    "start_time": "2021-08-04T20:51:31.687Z"
   },
   {
    "duration": 59,
    "start_time": "2021-08-04T20:51:32.433Z"
   },
   {
    "duration": 10,
    "start_time": "2021-08-04T20:51:32.494Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-04T20:51:32.506Z"
   },
   {
    "duration": 7,
    "start_time": "2021-08-04T20:51:32.516Z"
   },
   {
    "duration": 1337,
    "start_time": "2021-08-06T18:57:38.692Z"
   },
   {
    "duration": 6081,
    "start_time": "2021-08-06T18:57:40.031Z"
   },
   {
    "duration": 1899,
    "start_time": "2021-08-06T18:57:46.114Z"
   },
   {
    "duration": 42,
    "start_time": "2021-08-06T18:57:48.015Z"
   },
   {
    "duration": 11,
    "start_time": "2021-08-06T18:57:48.058Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-06T18:57:48.070Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-06T18:57:48.078Z"
   },
   {
    "duration": 8,
    "start_time": "2021-08-06T18:57:48.083Z"
   },
   {
    "duration": 6,
    "start_time": "2021-08-06T18:57:48.093Z"
   },
   {
    "duration": 1337,
    "start_time": "2021-08-06T18:57:48.101Z"
   },
   {
    "duration": 1174,
    "start_time": "2021-08-06T18:59:48.137Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-06T19:00:25.937Z"
   },
   {
    "duration": 1382,
    "start_time": "2021-08-06T19:00:26.835Z"
   },
   {
    "duration": 279,
    "start_time": "2021-08-06T19:01:14.317Z"
   },
   {
    "duration": 939,
    "start_time": "2021-08-06T19:01:19.977Z"
   },
   {
    "duration": 1456,
    "start_time": "2021-08-06T19:01:38.635Z"
   }
  ],
  "colab": {
   "collapsed_sections": [],
   "name": "notebook (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
